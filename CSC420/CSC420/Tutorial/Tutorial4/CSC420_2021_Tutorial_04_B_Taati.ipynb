{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "CSC420_2021_Tutorial_04_B.Taati.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRevpOVFhbJ8"
      },
      "source": [
        "#Tutorial 4\n",
        "\n",
        "#CSC420 - Fall 2021\n",
        "\n",
        "#Babak Taati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmA6U28aXTDm"
      },
      "source": [
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJsaIuyPXtoG"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SCC1oX2Xm30"
      },
      "source": [
        "# install OpenCV\n",
        "!pip install opencv-python\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqldsyvh8T7O"
      },
      "source": [
        "def imshowBGR(im):\n",
        "  img = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "  plt.figure(figsize=(7,7))\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "  return\n",
        "\n",
        "def imshowGray(gray):\n",
        "  plt.figure(figsize=(7,7))\n",
        "  plt.imshow(gray, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  return  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGA_63-mhf4Z"
      },
      "source": [
        "# image pyramids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIlKKNQAXm8-"
      },
      "source": [
        "img = cv2.imread('/content/drive/My Drive/window.jpg') \n",
        "\n",
        "imshowBGR(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9lhacvRX0ve"
      },
      "source": [
        "lowres = cv2.pyrDown(img)\n",
        "lowres = cv2.pyrDown(lowres)\n",
        "lowres = cv2.pyrDown(lowres) # you can also specify dstsize and borderType\n",
        "\n",
        "imshowBGR(lowres)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDclD9_ZX3xz"
      },
      "source": [
        "print(img.shape)\n",
        "\n",
        "# what do you expect the size of lowres to be?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHxfMIPK9hJI"
      },
      "source": [
        "lowres.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWUcc7ztX4bO"
      },
      "source": [
        "# does this work?\n",
        "lowres2 = img[::8,::8,:] # take every other 8 pixel\n",
        "print(lowres2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BtF29o2X4mM"
      },
      "source": [
        "imshowBGR(lowres2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc_hNyhIX4w_"
      },
      "source": [
        "highres = cv2.pyrUp(lowres) # upsamples & then blurs\n",
        "highres = cv2.pyrUp(highres)\n",
        "highres = cv2.pyrUp(highres)\n",
        "\n",
        "imshowBGR(highres)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq_NudbK3zYD"
      },
      "source": [
        "print(lowres.shape)\n",
        "print(highres.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NrUb9A58wrR"
      },
      "source": [
        "# Some other potentially useful stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGTkXzMh9GEs"
      },
      "source": [
        "1. counting cheerios, and learning about:\n",
        "* Contrast Limited Adaptive Histogram Equalization, \n",
        "* Otsu's method, and\n",
        "* Contours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOZ-JlIffVeV"
      },
      "source": [
        "img = cv2.imread('/content/drive/My Drive/cheerios.jpg') \n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "\n",
        "ax1.imshow(cv2.cvtColor(img,cv2.cv2.COLOR_BGR2RGB))\n",
        "ax1.title.set_text('RGB'), ax1.set_xticks([]), ax1.set_yticks([])\n",
        "ax2.imshow(gray,cmap = 'gray')\n",
        "ax2.title.set_text('Gray'), ax2.set_xticks([]), ax2.set_yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCmtU4JzaLA_"
      },
      "source": [
        "how many cheerios?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nOGDNKQP8iK"
      },
      "source": [
        "# Contrast Limited Adaptive Histogram Equalization (CLAHE)\n",
        "# https://docs.opencv.org/4.5.0/d5/daf/tutorial_py_histogram_equalization.html \n",
        "\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(9,9))\n",
        "cl1 = clahe.apply(gray)\n",
        "\n",
        "imshowGray(cl1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET60wA6ZZcQj"
      },
      "source": [
        "hist = cv2.calcHist([cl1],[0],None,[256],[0,256])\n",
        "plt.plot(hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCM8dBCyJovA"
      },
      "source": [
        "ret,th = cv2.threshold(cl1,100,255,cv2.THRESH_BINARY) # try different numbers. Can you find a threshold that gets all the edges, but nothing else?\n",
        "\n",
        "# also try with gray instead of gray2 to notice the difference\n",
        "\n",
        "print(ret)\n",
        "imshowGray(th)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBdyCnX84OiE"
      },
      "source": [
        "# another way: OTSU thresholding - automatically finds the threshold\n",
        "# https://youtu.be/jUUkMaNuHP8?t=34\n",
        "ret,th1 = cv2.threshold(cl1,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU) # \n",
        "\n",
        "print(ret)\n",
        "imshowGray(th1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AlzM4RER6xi"
      },
      "source": [
        "# morphologial erosion\n",
        "kernel = np.ones((3,3),np.uint8)\n",
        "th2 = cv2.erode(th1,kernel,iterations = 2) # iterations=1 if not using Otsu\n",
        "\n",
        "imshowGray(th2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur6eDWmZSCVG"
      },
      "source": [
        "# morphologial dilation\n",
        "kernel = np.ones((3,3),np.uint8)\n",
        "th3 = cv2.dilate(th2,kernel,iterations = 4) # use iterations=5 if not using Otsu\n",
        "\n",
        "imshowGray(th3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwPXnDdaSWJE"
      },
      "source": [
        "# find contours\n",
        "# https://docs.opencv.org/master/d9/d8b/tutorial_py_contours_hierarchy.html\n",
        "\n",
        "contours, hierarchy = cv2.findContours(th3, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE) # RETR_CCOMP: find niternal and external contours"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fSpRhaQZhZA"
      },
      "source": [
        "print(type(contours))\n",
        "print(len(contours))\n",
        "print(type(hierarchy))\n",
        "print(hierarchy.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8RxajM1Z5C8"
      },
      "source": [
        "hierarchy # 4th \"column\":   == -1 : external\n",
        "          #                 >=  0 : internal (equal numbers means inside the same external contour)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmbeB1_ZacaI"
      },
      "source": [
        "hierarchy.shape # 1 x 20 x 4 tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay9Vg3S8bxw_"
      },
      "source": [
        "print(hierarchy[0][:,-1]) # the last \"column\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOhnii92b10f"
      },
      "source": [
        "cheerio_count = np.count_nonzero(hierarchy[0][:,3]==-1)\n",
        "print('number of cheerios in the image = ', cheerio_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vtUYOU_czjA"
      },
      "source": [
        "# Draw all countours\n",
        "\n",
        "# Set up empty array the same size as the image\n",
        "countour_img = np.zeros(th3.shape)  \n",
        "\n",
        "for i in range(len(contours)):\n",
        "  if hierarchy[0][i][3] == -1: # external countour\n",
        "    cv2.drawContours(countour_img, contours, i, 255, -1)\n",
        "  else: # internal contour\n",
        "    cv2.drawContours(countour_img, contours, i, 150, -1)\n",
        "\n",
        "imshowGray(countour_img)\n",
        "\n",
        "# or try it this way:\n",
        "# plt.figure(figsize=(7,7))\n",
        "# plt.imshow(countour_img)\n",
        "# plt.xticks([]), plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM3wU4ES9IYu"
      },
      "source": [
        "2. Central Limit Theorem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6eMnqFHfn1E"
      },
      "source": [
        "n = 3\n",
        "A = np.random.uniform(low=-1, high=3, size=(100000,n)) # A[:,i] is 100,000 samples with uniform distribution\n",
        "B = np.random.exponential(scale=1., size=(100000,n))   # B[:,j] is 100,000 samples with exponential distribution\n",
        "\n",
        "X = A\n",
        "# X = B\n",
        "# X = A + B\n",
        "\n",
        "a = X[:,:1]           \n",
        "b = np.sum(X,axis=1)  \n",
        "\n",
        "\n",
        "hist,bins = np.histogram(a, bins=50) \n",
        "plt.hist(a, bins) \n",
        "plt.title(\"histogram of a\") \n",
        "plt.show()\n",
        "\n",
        "hist,bins = np.histogram(b, bins=50) \n",
        "plt.hist(b, bins) \n",
        "plt.title(\"histogram of b\") \n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP_iUwdL1cPG"
      },
      "source": [
        "3. Viola-Jones (face) detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6QnZl4VigIa"
      },
      "source": [
        "img = cv2.imread('/content/drive/My Drive/ID.jpg') \n",
        "# img = cv2.imread('/content/drive/My Drive/NT.jpg') \n",
        "\n",
        "imshowBGR(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "993MlW9m3wiE"
      },
      "source": [
        "#face_detector = cv2.CascadeClassifier('/content/drive/My Drive/haarcascade_frontalface_default.xml') \n",
        "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') \n",
        "\n",
        "#eyes_detector = cv2.CascadeClassifier('/content/drive/My Drive/haarcascade_eye_tree_eyeglasses.xml')\n",
        "eyes_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye_tree_eyeglasses.xml') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYlWPeUL4PFz"
      },
      "source": [
        "face_boxes = face_detector.detectMultiScale(img) # 'multi scale' reminds us of image pyramids\n",
        "eyes_boxes = eyes_detector.detectMultiScale(img) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qMzYu8L4iMy"
      },
      "source": [
        "face_boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX8byLpC5V8s"
      },
      "source": [
        "eyes_boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXchRlc-5X4U"
      },
      "source": [
        "for (x,y,w,h) in face_boxes: \n",
        "  cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0), 5) \n",
        "\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(cv2.cvtColor(img,cv2.cv2.COLOR_RGB2BGR))\n",
        "plt.xticks([]), plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCVm6NQZ5mqE"
      },
      "source": [
        "for (x,y,w,h) in eyes_boxes: \n",
        "  cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0), 5) \n",
        "\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(cv2.cvtColor(img,cv2.cv2.COLOR_RGB2BGR))\n",
        "plt.xticks([]), plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSJTWi937AMA"
      },
      "source": [
        "**practice:** write a program to show the live camera feed with blurred faces *italicized text*"
      ]
    }
  ]
}