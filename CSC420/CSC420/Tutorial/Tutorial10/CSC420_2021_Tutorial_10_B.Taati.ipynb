{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knMtBl4l22Wp"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UGZKH2Y3EtB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqUBOoGd71iZ"
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "B1Apuj3523ym",
    "outputId": "f7993be5-35e2-4e4f-92dc-46dea19b4fc5"
   },
   "outputs": [],
   "source": [
    "# generate fake data\n",
    "A = np.random.normal(loc=(-3,7), scale=2, size=(350,2))\n",
    "B = np.random.uniform(low=-1, high=3, size=(450,2)) # A[:,i] is 100,000 samples with uniform distribution\n",
    "C = np.random.chisquare(df=2, size=(400,2)) - 4  # B[:,j] is 100,000 samples with exponential distribution\n",
    "D = np.random.normal(loc=(-6,-1), scale=1.1, size=(200,2))\n",
    "X = np.concatenate((A, B, C,D), axis=0)\n",
    "\n",
    "plt.plot(X[:,0], X[:,1], '.', color='black', markersize=3);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUwrIYTT7ww_"
   },
   "source": [
    "## k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_iiNRTP8GIj"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zrDDVJbm26Ic",
    "outputId": "97a54e3d-9674-474d-dd79-44d42f44e940"
   },
   "outputs": [],
   "source": [
    "kmeans_clusters = KMeans(n_clusters=4, random_state=0).fit(X) # also try running with n_clusters 3 or 5\n",
    "                                                \n",
    "print(kmeans_clusters.labels_.shape)\n",
    "print(kmeans_clusters.labels_[0:-1:20])\n",
    "print(kmeans_clusters.cluster_centers_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "HUnB17k96vWo",
    "outputId": "c78adec6-6b78-4cbd-cf05-4c2fd1b78505"
   },
   "outputs": [],
   "source": [
    "cluster_count = len(kmeans_clusters.cluster_centers_)\n",
    "\n",
    "for i in range(0,cluster_count): # random colours\n",
    "  r = np.random.random()**2  \n",
    "  g = np.random.random()**2\n",
    "  b = np.random.random()**2\n",
    "  c = (r, g, b)\n",
    "\n",
    "  plt.plot(X[kmeans_clusters.labels_==i,0], X[kmeans_clusters.labels_==i,1], '.', color=c,markersize=3);\n",
    "  plt.plot(kmeans_clusters.cluster_centers_[i,0], kmeans_clusters.cluster_centers_[i,1], 'o', color=c, markersize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNbOqgDI8LyL"
   },
   "source": [
    "## Mean shift clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uqqfU3ZO8Hrl"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "If9ytdjW9_Ge",
    "outputId": "274bfad0-b171-43d9-b809-85fa50a34752"
   },
   "outputs": [],
   "source": [
    "meanshift_clusters = MeanShift(bandwidth=3.1).fit(X) # also try with other values of bandwidth\n",
    "\n",
    "cluster_count = len(meanshift_clusters.cluster_centers_)\n",
    "\n",
    "print(cluster_count)\n",
    "print(meanshift_clusters.labels_[0:1500:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lh3iIQV2ACdR",
    "outputId": "c7a7187d-a684-4be8-82f1-8997a9fa59a5"
   },
   "outputs": [],
   "source": [
    "meanshift_clusters.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "9DmTpGMu8a00",
    "outputId": "4f87d4d7-2458-45e3-8a51-aee021640649"
   },
   "outputs": [],
   "source": [
    "for i in range(0,cluster_count) :\n",
    "  r = np.random.random()\n",
    "  b = np.random.random()\n",
    "  g = np.random.random()\n",
    "  c = (r, g, b)\n",
    "  plt.plot(X[meanshift_clusters.labels_==i,0], X[meanshift_clusters.labels_==i,1], '.', color=c, markersize=3);\n",
    "  plt.plot(meanshift_clusters.cluster_centers_[i,0], meanshift_clusters.cluster_centers_[i,1], 'o', color=c, markersize=20)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6JlFnS9yDxN"
   },
   "source": [
    "## Clustering for (very simple) Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hVQ7gSrl0M9-",
    "outputId": "e404dbf9-71d3-4b00-8f55-79db3a9c718e"
   },
   "outputs": [],
   "source": [
    "if False: # only if you're running this in colab\n",
    "    # mount your google drive\n",
    "    from google.colab import drive\n",
    "\n",
    "    # This will prompt for authorization.\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixeZuJc20Yo_",
    "outputId": "0af3c26a-a7df-4ee1-f804-3a7cd6e3f274"
   },
   "outputs": [],
   "source": [
    "if False: # only if you're running this in colab\n",
    "    !pip install opencv-python\n",
    "\n",
    "import cv2\n",
    "from sklearn.cluster import estimate_bandwidth # to automatically estimate a good bandwidth for mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "l9N5m2pvwQyZ",
    "outputId": "ba312054-afe0-4691-bf8e-9c4a4000c870"
   },
   "outputs": [],
   "source": [
    "if False: # only if you're running this in colab\n",
    "    img = cv2.imread('/content/drive/My Drive/256px-Fruits.png')\n",
    "else:\n",
    "    img = cv2.imread('256px-Fruits.png')\n",
    "\n",
    "# img = cv2.bilateralFilter(img,30,40,75) \n",
    "\n",
    "img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img2)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EunfjU9B6rAi"
   },
   "outputs": [],
   "source": [
    "# let's cluster based on R, G, B, and x and y pixel coordinates\n",
    "x_coords, y_coords = np.meshgrid(range(img.shape[0]), range(img.shape[1]), indexing='ij')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hQ5wEZDH62ak",
    "outputId": "5f6e8f15-94f3-40d5-9903-b9b3399fd303"
   },
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "print(x_coords.shape)\n",
    "print(y_coords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXaRTIFL9hdn",
    "outputId": "f1060262-cd7f-4c85-eb26-75dce010bd7f"
   },
   "outputs": [],
   "source": [
    "x_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_GFogrT6bSta",
    "outputId": "5cc51077-f290-4447-b7c1-57a15411c251"
   },
   "outputs": [],
   "source": [
    "y_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpIoOAMcz_9t"
   },
   "outputs": [],
   "source": [
    "# flatten the image, and x and y coordinates\n",
    "\n",
    "flat_img = img.reshape((-1,3))\n",
    "flat_img = np.float32(flat_img)\n",
    "flat_img = flat_img / flat_img.max()\n",
    "\n",
    "flat_x = x_coords.reshape(-1)\n",
    "flat_x = np.float32(flat_x)\n",
    "flat_x = flat_x / flat_x.max() \n",
    "\n",
    "flat_y = y_coords.reshape(-1)\n",
    "flat_y = np.float32(flat_y)\n",
    "flat_y = flat_y / flat_y.max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q5yECt8h-y54",
    "outputId": "b097a66b-0eaf-4396-b772-bf00322501f5"
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "  # concat to make an N x 5 vector\n",
    "  f = np.column_stack((flat_img, flat_x, flat_y))\n",
    "\n",
    "else:\n",
    "  # just use RGB (and not x & y)\n",
    "  f = flat_img\n",
    "\n",
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1W0hzsIn-FZA",
    "outputId": "8b869d60-e62b-4410-b95d-4cc5109f5abd"
   },
   "outputs": [],
   "source": [
    "# estimate bandwidth\n",
    "bandwidth = estimate_bandwidth(f, quantile=.05, n_samples=2000)\n",
    "print(bandwidth)\n",
    "\n",
    "# # or manually set\n",
    "# bandwidth = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6U0QJXY-yK1"
   },
   "outputs": [],
   "source": [
    "use_meanshift = True # use k-means if false\n",
    "\n",
    "if use_meanshift: # use meanshift to cluster f\n",
    "  ms = MeanShift(bandwidth=bandwidth,bin_seeding=True)\n",
    "  ms.fit(f)\n",
    "  labels = ms.labels_\n",
    "else:\n",
    "  kmeans_clusters = KMeans(n_clusters=10, random_state=0).fit(f) # also try running with n_clusters 3 or 5\n",
    "  labels = kmeans_clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vkDs-7sXdxs9",
    "outputId": "27701b2e-1ef8-4654-a7f8-8af4c2863434"
   },
   "outputs": [],
   "source": [
    "segments = np.unique(labels)\n",
    "print(segments)\n",
    "print('# segments: ', segments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9uar0CSCAhh"
   },
   "outputs": [],
   "source": [
    "I = np.reshape(labels, (img.shape[0],img.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "GPrlc9P13x5S",
    "outputId": "8b618a7d-e9c1-4d21-f67f-6aeb9854e0c4"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10));\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax1.imshow(img2)\n",
    "ax1.title.set_text('Image'), ax1.set_xticks([]), ax1.set_yticks([])\n",
    "ax2.imshow(I,cmap = 'jet')\n",
    "ax2.title.set_text('Segments'), ax2.set_xticks([]), ax2.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean shift tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reminder about HSV (hue / saturation / value) colour space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/HSV_cone.png/1200px-HSV_cone.png width=\"350\"/>\n",
    "<img src=https://www.virtualartacademy.com/wp-content/uploads/2018/12/hue-saturation-value.png width=\"500\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # camera feed\n",
    "\n",
    "# capture one frame\n",
    "ret,frame = cap.read()\n",
    "\n",
    "# detect a face on the first frame\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') \n",
    "face_boxes = face_detector.detectMultiScale(frame) \n",
    "\n",
    "if len(face_boxes)==0:\n",
    "    print('no face detected')\n",
    "    assert(False)\n",
    "\n",
    "# initialize the tracing window around the (first) detected face\n",
    "(x,y,w,h) = tuple(face_boxes[0]) \n",
    "track_window = (x,y,w,h)\n",
    "\n",
    "#  region of interest for tracking\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "# convert the roi to HSV so we can construct a histogram of Hue \n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# why do we need this mask? (remember the cone?)\n",
    "# read the description for Figure 3 in the original Cam Shift paper: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.7673 \n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "\n",
    "\n",
    "# form histogram of hue in the roi\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "\n",
    "# normalize the histogram array values so they are in the min=0 to max=255 range\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# termination criteria for mean shift: 10 iteration or shift less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # grab a frame\n",
    "    ret ,frame = cap.read() \n",
    "    \n",
    "    if ret == True: \n",
    "  \n",
    "        # convert to HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # histogram back projection using roi_hist \n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        \n",
    "        # use meanshift to shift the tracking window\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "        \n",
    "        # display tracked window\n",
    "        x,y,w,h = track_window\n",
    "        img = cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255),5)\n",
    "        \n",
    "        cv2.imshow('mean shift tracking demo',img)\n",
    "        \n",
    "        if cv2.waitKey(33) & 0xFF == 27: # wait a bit and exit is ESC is pressed\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cam shift tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # camera feed\n",
    "\n",
    "# capture one frame\n",
    "ret,frame = cap.read()\n",
    "\n",
    "# detect a face on the first frame\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') \n",
    "face_boxes = face_detector.detectMultiScale(frame) \n",
    "\n",
    "if len(face_boxes)==0:\n",
    "    print('no face detected')\n",
    "    assert(False)\n",
    "\n",
    "# initialize the tracing window around the (first) detected face\n",
    "(x,y,w,h) = tuple(face_boxes[0]) \n",
    "track_window = (x,y,w,h)\n",
    "\n",
    "#  region of interest for tracking\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "# convert the roi to HSV so we can construct a histogram of Hue \n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# why do we need this mask? (remember the cone?)\n",
    "# read the description for Figure 3 in the original Cam Shift paper: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.7673 \n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "\n",
    "\n",
    "# form histogram of hue in the roi\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "\n",
    "# normalize the histogram array values so they are in the min=0 to max=255 range\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# termination criteria for mean shift: 10 iteration or shift less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # grab a frame\n",
    "    ret ,frame = cap.read() \n",
    "    \n",
    "    if ret == True: \n",
    "  \n",
    "        # convert to HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # histogram back projection using roi_hist \n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        \n",
    "        # apply camshift to get the new location\n",
    "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "        \n",
    "        # Draw it on image\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = np.int0(pts)\n",
    "        img = cv2.polylines(frame,[pts],True, 255,2)\n",
    "\n",
    "        cv2.imshow('cam shift tracking demo',img)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == 27: # wait 1 ms and exit is ESC is pressed\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "k_means_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
