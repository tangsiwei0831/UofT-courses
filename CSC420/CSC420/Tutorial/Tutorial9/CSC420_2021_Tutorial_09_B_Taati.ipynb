{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSC420_2021_Tutorial_09_B.Taati.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnDfJ2uFntNj"
      },
      "source": [
        "# Tutorial 9\n",
        "# CSC420 - Fall 2021\n",
        "# Babak Taati"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asDUk-yKnvPK"
      },
      "source": [
        "affine transformations, SIFT (and SURF and ORB), and RANSAC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owh6dFVspsB_"
      },
      "source": [
        "# the usual\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install opencv-python\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uFW0YnvqDdV"
      },
      "source": [
        "Part 1: affine transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70StJqM53hB7"
      },
      "source": [
        "# draw a rectangle\n",
        "img = np.zeros(shape=[512, 512], dtype=np.uint8)\n",
        "img[50:200,100:350]=255\n",
        "plt.imshow(img, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYDzjXFL6vna"
      },
      "source": [
        "# translation\n",
        "rows, cols = img.shape \n",
        "M = np.array([[1.0, 0, 150], [0, 1, 150]])\n",
        "dst = cv2.warpAffine(img, M, (cols, rows))\n",
        "plt.imshow(dst, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T3LF8MV7PTR"
      },
      "source": [
        "# rotation\n",
        "theta = np.pi / 6\n",
        "M = np.array([[np.cos(theta), -np.sin(theta), 0], [np.sin(theta), np.cos(theta), 0]])\n",
        "print(M)\n",
        "dst = cv2.warpAffine(img, M, (cols, rows))\n",
        "plt.imshow(dst, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIezKKi68lM3"
      },
      "source": [
        "# shear\n",
        "M = np.array([[.3, 0.1, 0], [0, 1.3, 0]])\n",
        "dst = cv2.warpAffine(img, M, (cols, rows))\n",
        "plt.imshow(dst, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUVAdUwGCC3X"
      },
      "source": [
        "# random affine transform\n",
        "M = np.random.rand(2,3)\n",
        "dst = cv2.warpAffine(img, M, (cols, rows))\n",
        "plt.imshow(dst, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcg7G2m35uTV"
      },
      "source": [
        "# calculate an affine transform based on point matches\n",
        "pts1 = np.float32([[10, 10], \n",
        "                   [20, 30],  \n",
        "                   [30, 40]]) \n",
        "  \n",
        "pts2 = np.float32([[19, 20], \n",
        "                   [30, 39],  \n",
        "                   [40, 52]]) \n",
        "  \n",
        "M = cv2.getAffineTransform(pts1, pts2) # least squares (if more than 3 point matches given)\n",
        "dst = cv2.warpAffine(img, M, (cols, rows))\n",
        "plt.imshow(dst, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbSiwf6iqTjo"
      },
      "source": [
        "Part 2: SIFT (and SURF and ORB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR-Gu4NvZCiI"
      },
      "source": [
        "!pip install  opencv-contrib-python==3.4.2.17 # otherwise you'd get an error message saying this when you try to use SIFT\n",
        "                                   # This algorithm is patented and is excluded in this configuration; \n",
        "                                   # Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in \n",
        "                                   # function 'cv::xfeatures2d::SIFT::create'\n",
        "\n",
        "                                   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhYUIkRj-LwF"
      },
      "source": [
        "# mount your google drive\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQe5zRcwCt72"
      },
      "source": [
        "# load two images\n",
        "img1 = cv2.imread(\"/content/drive/My Drive/Book_cover.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "img2 = cv2.imread(\"/content/drive/My Drive/Book_pic.png\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img1, cmap='gray')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(img2, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4y4taGOCuj1"
      },
      "source": [
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "surf = cv2.xfeatures2d.SURF_create() # read about SURF here: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_surf_intro/py_surf_intro.html\n",
        "orb = cv2.ORB_create(nfeatures=1000) # read about ORB here: https://docs.opencv.org/3.4/d1/d89/tutorial_py_orb.html "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCSH8gvFEtz0"
      },
      "source": [
        "kp1_SIFT, desc1_SIFT = sift.detectAndCompute(img1, None)\n",
        "kp2_SIFT, desc2_SIFT = sift.detectAndCompute(img2, None)\n",
        "\n",
        "kp1_SURF, desc1_SURF = surf.detectAndCompute(img1, None)\n",
        "kp2_SURF, desc2_SURF = surf.detectAndCompute(img2, None)\n",
        "\n",
        "kp1_ORB, desc1_ORB = orb.detectAndCompute(img1, None)\n",
        "kp2_ORB, desc2_ORB = orb.detectAndCompute(img2, None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmwHpTwDFoaY"
      },
      "source": [
        "img1_SIFT = cv2.drawKeypoints(img1, kp1_SIFT, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, color=(255,255,0))\n",
        "img2_SIFT = cv2.drawKeypoints(img2, kp1_SIFT, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, color=(255,255,0))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img1_SIFT)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(img2_SIFT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKl3HnOtWHba"
      },
      "source": [
        "img1_SURF = cv2.drawKeypoints(img1, kp1_SURF, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, color=(200,0,0))\n",
        "img2_SURF = cv2.drawKeypoints(img2, kp1_SURF, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, color=(200,0,0))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img1_SURF)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(img2_SURF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WbM_otBWM8L"
      },
      "source": [
        "img1_ORB = cv2.drawKeypoints(img1, kp1_ORB, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, color=(0,255,0))\n",
        "img2_ORB = cv2.drawKeypoints(img2, kp1_ORB, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, color=(0,255,0))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img1_ORB)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(img2_ORB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg57fL9JOZil"
      },
      "source": [
        "# which keypoints/descriptor to use?\n",
        "\n",
        "kp1 = kp1_SIFT\n",
        "kp2 = kp2_SIFT\n",
        "desc1 = desc1_SIFT\n",
        "desc2 = desc2_SIFT\n",
        "\n",
        "# kp1 = kp1_SURF\n",
        "# kp2 = kp2_SURF\n",
        "# desc1 = desc1_SURF\n",
        "# desc2 = desc2_SURF\n",
        "\n",
        "# kp1 = kp1_ORB\n",
        "# kp2 = kp2_ORB\n",
        "# desc1 = desc1_ORB\n",
        "# desc2 = desc2_ORB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoKj3kasXBj_"
      },
      "source": [
        "# (brute force) matching of descriptors\n",
        "bf = cv2.BFMatcher()\n",
        "matches = bf.knnMatch(desc1, desc2, k=2) # k=2 means find the top two matchs for each query descriptor\n",
        "\n",
        "# Apply ratio test (as per David Lowe's SIFT paper: compare the best match with the 2nd best match_\n",
        "good_matches = []\n",
        "good_matches_without_list = []\n",
        "for m,n in matches:\n",
        "    if m.distance < 0.75*n.distance: # only accept matchs that are considerably better than the 2nd best match\n",
        "        good_matches.append([m])\n",
        "        good_matches_without_list.append(m) # this is to simplify finding a homography later\n",
        "\n",
        "img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good_matches,\n",
        "                          None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS, \n",
        "                          matchColor=(0,255,0))\n",
        "plt.imshow(img3),plt.show()\n",
        "\n",
        "# you can also an approximate (but fast) nearest neighbour algorithm called FLANN. See here:\n",
        "# https://docs.opencv.org/master/dc/dc3/tutorial_py_matcher.html\n",
        "# FLANN = Fast Library for Approximate Nearest Neighbour\n",
        "\n",
        "# paper: https://ieeexplore.ieee.org/iel7/34/4359286/06809191.pdf "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38fmOTUimkQB"
      },
      "source": [
        "# how do you think FLANN might work?\n",
        "## remember k-d trees from your data structure class? (and more ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQNbj9A5r4zg"
      },
      "source": [
        "Part 3: RANSAC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGSQdhBxhutC"
      },
      "source": [
        "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches_without_list ]).reshape(-1,1,2)\n",
        "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches_without_list ]).reshape(-1,1,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpgUzQBtmjjP"
      },
      "source": [
        "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
        "\n",
        "h,w = img1.shape\n",
        "pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
        "detected_book = cv2.perspectiveTransform(pts,M)\n",
        "\n",
        "img3 = cv2.polylines(img2.copy(),[np.int32(detected_book)],True,255,3, cv2.LINE_AA)\n",
        "plt.imshow(img3, 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysl5_vjFLu8-"
      },
      "source": [
        "img4 = cv2.drawMatchesKnn(img1,kp1,img3,kp2,good_matches,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS, matchColor=(0,255,0))\n",
        "plt.imshow(img4),plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRnarhG0RMFN"
      },
      "source": [
        "# warp the book cover to align with the other picture\n",
        "\n",
        "h,w = img2.shape\n",
        "warped = cv2.warpPerspective(img1, M, (w, h))\n",
        "plt.imshow(warped, cmap='gray')\n",
        "\n",
        "img2_book_only = cv2.bitwise_and(img2, warped)\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(warped, cmap='gray')\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(img2, cmap='gray')\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(img2_book_only, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ-4CANn6oKd"
      },
      "source": [
        "# what do you expect to see if we do this:\n",
        "\n",
        "overlaid = np.zeros((h,w,3))\n",
        "overlaid[:,:,0] = img2  # or img2_book_only\n",
        "overlaid[:,:,1] = img2  # or img2_book_only\n",
        "overlaid[:,:,2] = warped\n",
        "\n",
        "plt.figure(figsize=(25,25))\n",
        "plt.imshow(np.uint8(overlaid))\n",
        "plt.xticks([]), plt.yticks([])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyL7v123JSHN"
      },
      "source": [
        "fig = plt.figure(figsize=(20,20))\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax2 = fig.add_subplot(122)\n",
        "\n",
        "ax1.imshow(img1,cmap = 'gray')\n",
        "ax1.title.set_text('RGB'), ax1.set_xticks([]), ax1.set_yticks([])\n",
        "ax2.imshow(img2,cmap = 'gray')\n",
        "ax2.title.set_text('Gray'), ax2.set_xticks([]), ax2.set_yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3St2R-jJoHE"
      },
      "source": [
        "res = cv2.bitwise_and(img2, warped)\n",
        "plt.imshow(res)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}