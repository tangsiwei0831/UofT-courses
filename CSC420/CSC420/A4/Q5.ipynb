{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of A4Q5",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlZw8qj-Siaa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZM4Q-lUSm6B"
      },
      "source": [
        "from sklearn.cluster import MeanShift\n",
        "!pip install opencv-python\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import estimate_bandwidth # to automatically estimate a good bandwidth for mean shift\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2eXH1Dryied"
      },
      "source": [
        "5.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gsgQwaa4P59"
      },
      "source": [
        "cap = cv2.VideoCapture('/content/drive/My Drive/KylianMbappe.mp4')\n",
        "# capture one frame\n",
        "ret,frame = cap.read()\n",
        "\n",
        "# detect a face on the first frame\n",
        "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') \n",
        "face_boxes = face_detector.detectMultiScale(frame) \n",
        "\n",
        "if len(face_boxes)==0:\n",
        "    print('no face detected')\n",
        "    assert(False)\n",
        "\n",
        "# initialize the tracing window around the (first) detected face\n",
        "(x,y,w,h) = tuple(face_boxes[0]) \n",
        "track_window = (x,y,w,h)\n",
        "\n",
        "#  region of interest for tracking\n",
        "roi = frame[y:y+h, x:x+w]\n",
        "\n",
        "# convert the roi to HSV so we can construct a histogram of Hue \n",
        "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# why do we need this mask? (remember the cone?)\n",
        "# read the description for Figure 3 in the original Cam Shift paper: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.7673 \n",
        "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
        "\n",
        "\n",
        "# form histogram of hue in the roi\n",
        "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
        "\n",
        "# normalize the histogram array values so they are in the min=0 to max=255 range\n",
        "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
        "\n",
        "# termination criteria for mean shift: 10 iteration or shift less than 1 pixel\n",
        "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
        "IoUs = [] \n",
        "frame_numbers = []\n",
        "frame_number = 2\n",
        "while True:\n",
        "    \n",
        "    # grab a frame\n",
        "    ret ,frame = cap.read()\n",
        "    \n",
        "    if ret == True: \n",
        "  \n",
        "        # convert to HSV\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        \n",
        "        # histogram back projection using roi_hist \n",
        "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
        "\n",
        "        # use meanshift to shift the tracking window\n",
        "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
        "        \n",
        "        # display tracked window\n",
        "        img = cv2.rectangle(frame,(track_window[0],track_window[1]), (track_window[0]+track_window[2],track_window[1]+track_window[3]), (0,0,255),5)\n",
        "\n",
        "        face_boxes = face_detector.detectMultiScale(frame)\n",
        "        if face_boxes == ():\n",
        "          continue\n",
        "        if face_boxes[0][0] + face_boxes[0][2] <=  track_window[0] + track_window[2]:\n",
        "          if face_boxes[0][0] >= track_window[0]:\n",
        "            inner_width = face_boxes[0][0] + face_boxes[0][2] -  face_boxes[0][0]\n",
        "          else:\n",
        "            inner_width = face_boxes[0][0] + face_boxes[0][2] - track_window[0]\n",
        "        else:\n",
        "          if face_boxes[0][0] >= track_window[0]:\n",
        "            inner_width = track_window[0] + track_window[2] -  face_boxes[0][0]\n",
        "          else:\n",
        "            inner_width = track_window[0] + track_window[2] - track_window[0]\n",
        "\n",
        "        if face_boxes[0][1] + face_boxes[0][3] <= track_window[1] + track_window[3]:\n",
        "          if face_boxes[0][1] >= track_window[1]:\n",
        "            inner_length = face_boxes[0][1] + face_boxes[0][3] - face_boxes[0][1]\n",
        "          else:\n",
        "            inner_length = face_boxes[0][1] + face_boxes[0][3] - track_window[1]\n",
        "        else:\n",
        "          if face_boxes[0][1] >= track_window[1]:\n",
        "            inner_length =  track_window[1] + track_window[3] - face_boxes[0][1]\n",
        "          else:\n",
        "            inner_length =  track_window[1] + track_window[3] - track_window[1]\n",
        "\n",
        "\n",
        "        inner_area = inner_width * inner_length\n",
        "        total_area = (face_boxes[0][2] * face_boxes[0][3]) + track_window[2] * track_window[3] - inner_area\n",
        "        IoU = inner_area/total_area\n",
        "        frame_numbers.append(frame_number)\n",
        "        frame_number += 1\n",
        "        IoUs.append(IoU)\n",
        "        print(IoU)\n",
        "        img = cv2.rectangle(frame, (face_boxes[0][0],face_boxes[0][1]), (face_boxes[0][0]+ face_boxes[0][2],face_boxes[0][1]+ face_boxes[0][3]), (0,255,0),5)\n",
        "        cv2_imshow(img)\n",
        "        \n",
        "        if cv2.waitKey(33) & 0xFF == 27: # wait a bit and exit is ESC is pressed\n",
        "            break  \n",
        "    else:\n",
        "        break\n",
        "        \n",
        "cv2.destroyAllWindows()\n",
        "cap.release()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CaV9a0IzsVUo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHIPvQpBwbv1"
      },
      "source": [
        "frame_number_array = np.array(frame_numbers)\n",
        "IoU_array = np.array(IoUs)\n",
        "plt.plot(frame_number_array, IoU_array)\n",
        "plt.xlabel('frame number')\n",
        "plt.ylabel('IoU')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAfSHTJMyefu"
      },
      "source": [
        "5.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvPmWzBXSqpj"
      },
      "source": [
        "cap = cv2.VideoCapture('/content/drive/My Drive/KylianMbappe.mp4')\n",
        "\n",
        "# capture one frame\n",
        "ret,frame = cap.read()\n",
        "\n",
        "# detect a face on the first frame\n",
        "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') \n",
        "face_boxes = face_detector.detectMultiScale(frame) \n",
        "\n",
        "if len(face_boxes)==0:\n",
        "    print('no face detected')\n",
        "    assert(False)\n",
        "\n",
        "# initialize the tracing window around the (first) detected face\n",
        "(x,y,w,h) = tuple(face_boxes[0]) \n",
        "track_window = (x,y,w,h)\n",
        "\n",
        "#  region of interest for tracking\n",
        "roi = frame[y:y+h, x:x+w]\n",
        "\n",
        "# # convert the roi to HSV so we can construct a histogram of Hue \n",
        "#hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# why do we need this mask? (remember the cone?)\n",
        "# read the description for Figure 3 in the original Cam Shift paper: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.7673 \n",
        "\n",
        "gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "img = cv2.GaussianBlur(gray_roi,(5,5),0)\n",
        "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)  # x\n",
        "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)  # y\n",
        "mag, ang = cv2.cartToPolar(sobelx, sobely, angleInDegrees=True)\n",
        "max_magnitude = np.amax(mag)\n",
        "mask = np.zeros((mag.shape[0],mag.shape[1]), dtype=\"uint8\")\n",
        "for i in range(mag.shape[0]):\n",
        "  for j in range(mag.shape[1]):\n",
        "    if 0.1 * max_magnitude < mag[i][j]:\n",
        "       mask[i][j] = gray_roi[i][j]\n",
        "# form histogram of hue in the roi\n",
        "roi_hist = cv2.calcHist([gray_roi],[0],mask,[180],[0,180])\n",
        "\n",
        "# normalize the histogram array values so they are in the min=0 to max=255 range\n",
        "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
        "\n",
        "# termination criteria for mean shift: 10 iteration or shift less than 1 pixel\n",
        "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
        "\n",
        "frame_number = 2\n",
        "frame_numbers = []\n",
        "IoUs = []\n",
        "while True:\n",
        "    \n",
        "    # grab a frame\n",
        "    ret ,frame = cap.read() \n",
        "    if ret == True: \n",
        "        face_boxes = face_detector.detectMultiScale(frame)\n",
        "        if face_boxes == ():\n",
        "          continue\n",
        "        (x_3,y_3,w_3,h_3) = tuple(face_boxes[0])\n",
        "        roi = frame[y_3:y_3+h_3, x_3:x_3+w_3]\n",
        "        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "        img = cv2.GaussianBlur(gray_roi,(5,5),0)\n",
        "        sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)  # x\n",
        "        sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)  # y\n",
        "        mag, ang = cv2.cartToPolar(sobelx, sobely, angleInDegrees=True)\n",
        "        max_magnitude = np.amax(mag)\n",
        "        mask = np.zeros((mag.shape[0],mag.shape[1]), dtype=\"uint8\")\n",
        "        for i in range(mag.shape[0]):\n",
        "          for j in range(mag.shape[1]):\n",
        "            if  0.1 * max_magnitude < mag[i][j]:\n",
        "              mask[i][j] = gray_roi[i][j]\n",
        "        # form histogram of hue in the roi\n",
        "        roi_hist = cv2.calcHist([gray_roi],[0],mask,[180],[0,180])\n",
        "\n",
        "        # # convert to HSV\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  \n",
        "        # histogram back projection using roi_hist \n",
        "        dst = cv2.calcBackProject([gray],[0],roi_hist,[0,180],1)\n",
        "        \n",
        "        # use meanshift to shift the tracking window\n",
        "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
        "        face_boxes = face_detector.detectMultiScale(frame)\n",
        "        if face_boxes[0][0] + face_boxes[0][2] <=  track_window[0] + track_window[2]:\n",
        "          if face_boxes[0][0] >= track_window[0]:\n",
        "            inner_width = face_boxes[0][0] + face_boxes[0][2] -  face_boxes[0][0]\n",
        "          else:\n",
        "            inner_width = face_boxes[0][0] + face_boxes[0][2] - track_window[0]\n",
        "        else:\n",
        "          if face_boxes[0][0] >= track_window[0]:\n",
        "            inner_width = track_window[0] + track_window[2] -  face_boxes[0][0]\n",
        "          else:\n",
        "            inner_width = track_window[0] + track_window[2] - track_window[0]\n",
        "\n",
        "        if face_boxes[0][1] + face_boxes[0][3] <= track_window[1] + track_window[3]:\n",
        "          if face_boxes[0][1] >= track_window[1]:\n",
        "            inner_length = face_boxes[0][1] + face_boxes[0][3] - face_boxes[0][1]\n",
        "          else:\n",
        "            inner_length = face_boxes[0][1] + face_boxes[0][3] - track_window[1]\n",
        "        else:\n",
        "          if face_boxes[0][1] >= track_window[1]:\n",
        "            inner_length =  track_window[1] + track_window[3] - face_boxes[0][1]\n",
        "          else:\n",
        "            inner_length =  track_window[1] + track_window[3] - track_window[1]\n",
        "        inner_area = inner_width * inner_length\n",
        "        total_area = face_boxes[0][2] * face_boxes[0][3] + track_window[2] * track_window[3] - inner_area\n",
        "        IoU = inner_area/total_area\n",
        "        frame_numbers.append(frame_number)\n",
        "        IoUs.append(IoU)\n",
        "        print(IoU)\n",
        "        x,y,w,h = track_window\n",
        "        img = cv2.rectangle(frame, (track_window[0],track_window[1]), (track_window[0]+track_window[2],track_window[1]+track_window[3]), (0,0,255),5)\n",
        "        img = cv2.rectangle(frame, (face_boxes[0][0],face_boxes[0][1]), (face_boxes[0][0]+ face_boxes[0][2],face_boxes[0][1]+ face_boxes[0][3]), (0,255,0),5)\n",
        "        cv2_imshow(img)\n",
        "        frame_number += 1\n",
        "\n",
        "        if cv2.waitKey(33) & 0xFF == 27: # wait a bit and exit is ESC is pressed\n",
        "            break\n",
        "    else:\n",
        "        break     \n",
        "cv2.destroyAllWindows()\n",
        "cap.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Uy0G3ZlSJn"
      },
      "source": [
        "frame_number_array = np.array(frame_numbers)\n",
        "IoU_array = np.array(IoUs)\n",
        "plt.plot(frame_number_array, IoU_array)\n",
        "plt.xlabel('frame number')\n",
        "plt.ylabel('IoU')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}